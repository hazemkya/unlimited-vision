{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# your model focuses on during captioning\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "#importing local module\n",
    "from models.subclasses import *\n",
    "from models.predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = int(config['config']['units'])\n",
    "embedding_dim = int(config['config']['embedding_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "val_image_paths, image_path_to_caption = import_files(shuffle= False, method = \"val\")\n",
    "\n",
    "val_captions = []\n",
    "img_name_vector = []\n",
    "for image_path in val_image_paths:\n",
    "  caption_list = image_path_to_caption[image_path]\n",
    "  val_captions.extend(caption_list)\n",
    "  img_name_vector.extend([image_path] * len(caption_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, vocabulary, _ = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, tokenizer, cap_vector = tokenization(val_captions, max_length, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, len(vocabulary))\n",
    "_, _, image_features_extract_model = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "img_name_val, cap_val = split_data(img_name_vector, cap_vector ,\n",
    "                                    image_features_extract_model, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2b4624c7070>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = []\n",
    "\n",
    "for i in range(len(img_name_val)):\n",
    "    references.append(' '.join([tf.compat.as_text(index_to_word(i).numpy())\n",
    "                         for i in cap_val[i] if i not in [0]]).split('<start>')[1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_references = []\n",
    "\n",
    "for i in range(0, len(img_name_val), 4):\n",
    "    list_of_references.append([references[i:i+4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' a man sleeping with his cat next to him',\n",
       " ' a young man and his cute cat enjoy a',\n",
       " ' a man is sleeping with his head on a',\n",
       " ' man sleeping in his bedroom next to a cat.']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Caption: ['a', 'man', 'sleeping', 'with', 'his', 'cat', 'next', 'to', 'him']\n",
      "Prediction Caption: ['a', 'is', 'man', 'plane', 'park', 'with', 'a', 'planes.', 'with', 'picture']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The number of hypotheses and their reference(s) should be the same ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hazem\\Desktop\\collage\\Graduation project\\Unlimited vision app\\evaluation.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Desktop/collage/Graduation%20project/Unlimited%20vision%20app/evaluation.ipynb#ch0000008?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mReal Caption:\u001b[39m\u001b[39m'\u001b[39m, references[\u001b[39mint\u001b[39m(num\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m)])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Desktop/collage/Graduation%20project/Unlimited%20vision%20app/evaluation.ipynb#ch0000008?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPrediction Caption:\u001b[39m\u001b[39m'\u001b[39m, result)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hazem/Desktop/collage/Graduation%20project/Unlimited%20vision%20app/evaluation.ipynb#ch0000008?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBLEU-1: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m corpus_bleu(list_of_references[num][\u001b[39m0\u001b[39;49m], list_of_hypotheses, weights\u001b[39m=\u001b[39;49m(\u001b[39m1.0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Desktop/collage/Graduation%20project/Unlimited%20vision%20app/evaluation.ipynb#ch0000008?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBLEU-2: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m corpus_bleu(list_of_references[num][\u001b[39m0\u001b[39m], list_of_hypotheses, weights\u001b[39m=\u001b[39m(\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hazem/Desktop/collage/Graduation%20project/Unlimited%20vision%20app/evaluation.ipynb#ch0000008?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBLEU-3: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m corpus_bleu(list_of_references[num][\u001b[39m0\u001b[39m], list_of_hypotheses, weights\u001b[39m=\u001b[39m(\u001b[39m0.3\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0\u001b[39m)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\translate\\bleu_score.py:195\u001b[0m, in \u001b[0;36mcorpus_bleu\u001b[1;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/hazem/AppData/Roaming/Python/Python39/site-packages/nltk/translate/bleu_score.py?line=191'>192</a>\u001b[0m p_denominators \u001b[39m=\u001b[39m Counter()  \u001b[39m# Key = ngram order, and value = no. of ngram in ref.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/hazem/AppData/Roaming/Python/Python39/site-packages/nltk/translate/bleu_score.py?line=192'>193</a>\u001b[0m hyp_lengths, ref_lengths \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/hazem/AppData/Roaming/Python/Python39/site-packages/nltk/translate/bleu_score.py?line=194'>195</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(list_of_references) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(hypotheses), (\n\u001b[0;32m    <a href='file:///c%3A/Users/hazem/AppData/Roaming/Python/Python39/site-packages/nltk/translate/bleu_score.py?line=195'>196</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThe number of hypotheses and their reference(s) should be the \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msame \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/hazem/AppData/Roaming/Python/Python39/site-packages/nltk/translate/bleu_score.py?line=196'>197</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/hazem/AppData/Roaming/Python/Python39/site-packages/nltk/translate/bleu_score.py?line=198'>199</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/hazem/AppData/Roaming/Python/Python39/site-packages/nltk/translate/bleu_score.py?line=199'>200</a>\u001b[0m     weights[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mAssertionError\u001b[0m: The number of hypotheses and their reference(s) should be the same "
     ]
    }
   ],
   "source": [
    "# captions on the test set\n",
    "# rid = np.random.randint(0, len(img_name_val))\n",
    "# image = img_name_val[rid]\n",
    "num = 0\n",
    "\n",
    "image = img_name_val[num]\n",
    "# real_caption = ' '.join([tf.compat.as_text(index_to_word(i).numpy())\n",
    "#                          for i in cap_val[rid] if i not in [0]]).split()\n",
    "\n",
    "result, attention_plot = evaluate(image, encoder, decoder, image_features_extract_model,\n",
    "                                    word_to_index, index_to_word)\n",
    "\n",
    "if result[-1] == \"<end>\":\n",
    "    result.remove(\"<end>\")\n",
    "# if real_caption[0] == \"<start>\":\n",
    "#     real_caption.remove(\"<start>\")\n",
    "\n",
    "\n",
    "list_of_hypotheses = [result]\n",
    "\n",
    "print('Real Caption:', references[int(num/4)])\n",
    "print('Prediction Caption:', result)\n",
    "print('BLEU-1: %f' % corpus_bleu(list_of_references[num], list_of_hypotheses, weights=(1.0, 0, 0, 0)))\n",
    "print('BLEU-2: %f' % corpus_bleu(list_of_references[num], list_of_hypotheses, weights=(0.5, 0.5, 0, 0)))\n",
    "print('BLEU-3: %f' % corpus_bleu(list_of_references[num], list_of_hypotheses, weights=(0.3, 0.3, 0.3, 0)))\n",
    "print('BLEU-4: %f' % corpus_bleu(list_of_references[num], list_of_hypotheses, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "plot_attention(image, result, attention_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_references[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['a', 'man', 'sleeping', 'with', 'his', 'cat', 'next', 'to', 'him'],\n",
       "  ['a', 'young', 'man', 'and', 'his', 'cute', 'cat', 'enjoy', 'a'],\n",
       "  ['a', 'man', 'is', 'sleeping', 'with', 'his', 'head', 'on', 'a'],\n",
       "  ['man', 'sleeping', 'in', 'his', 'bedroom', 'next', 'to', 'a', 'cat.']]]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', '[UNK]', 'is', 'an', 'with', 'a', 'runway', 'room', 'scene', 'a']]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'man', 'sleeping', 'with', 'his', 'cat', 'next', 'to', 'him'],\n",
       " ['a', 'young', 'man', 'and', 'his', 'cute', 'cat', 'enjoy', 'a'],\n",
       " ['a', 'man', 'is', 'sleeping', 'with', 'his', 'head', 'on', 'a'],\n",
       " ['man', 'sleeping', 'in', 'his', 'bedroom', 'next', 'to', 'a', 'cat.']]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_references[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0855005469a133b1a4fed7e6a9d3300657ffc4061414113a9f065e922aa0ee4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('uvapp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
