{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# You'll generate plots of attention in order to see which parts of an image\n",
    "# your model focuses on during captioning\n",
    "# from nltk.translate.bleu_score import corpus_bleu\n",
    "# from nltk.translate.meteor_score import meteor_score\n",
    "# from rouge import Rouge\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import configparser\n",
    "import re\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "import json\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "#importing local module \n",
    "from models.subclasses import *\n",
    "from models.utilities import *\n",
    "from models.predict import *\n",
    "from models.train_utils import *\n",
    "from models.evaluation_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_plot = load_loss()\n",
    "print(len(loss_plot))\n",
    "plt.plot(loss_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = int(config['config']['units'])\n",
    "embedding_dim = int(config['config']['embedding_dim'])\n",
    "\n",
    "vocabulary_size = int(config['config']['vocabulary_size'])\n",
    "\n",
    "\n",
    "use_glove = bool(config['config']['use_glove'])\n",
    "glove_dim = int(config['config']['glove_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "val_image_paths, image_path_to_caption_val = import_files(shuffle= False, method = \"val\")\n",
    "\n",
    "val_captions = []\n",
    "img_name_vector_val = []\n",
    "for image_path in val_image_paths:\n",
    "  caption_list = image_path_to_caption_val[image_path]\n",
    "  if len(caption_list)!=5:\n",
    "    caption_list = caption_list[:5]\n",
    "  val_captions.extend(caption_list)\n",
    "  img_name_vector_val.extend([image_path] * len(caption_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118287\n"
     ]
    }
   ],
   "source": [
    "train_image_paths, image_path_to_caption_train = import_files(shuffle= False, method = \"train\")\n",
    "\n",
    "train_captions = []\n",
    "img_name_vector_train = []\n",
    "for image_path in train_image_paths:\n",
    "  caption_list = image_path_to_caption_train[image_path]\n",
    "  if len(caption_list)!=5:\n",
    "    caption_list = caption_list[:5]\n",
    "  train_captions.extend(caption_list)\n",
    "  img_name_vector_train.extend([image_path] * len(caption_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591435"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, vocabulary, _ = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index_val, index_to_word_val, tokenizer_val, cap_vector_val = tokenization(val_captions, max_length, vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index_train, index_to_word_train, tokenizer_train, cap_vector_train = tokenization(train_captions, max_length, vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1581"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_glove_path = f\"./dataset/glove.6B/new_glove.6B.{glove_dim}d.pkl\"\n",
    "tuned_glove = pickle.load(open(new_glove_path, \"rb\"))\n",
    "len(tuned_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 401581 word vectors.\n",
      "Converted 23871 words (5771 misses)\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "if use_glove:\n",
    "    glove_path = f\"./dataset/glove.6B/glove.6B.{glove_dim}d.txt\"\n",
    "\n",
    "    with open(glove_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            word, coefs = line.split(maxsplit=1)\n",
    "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "    embeddings_index.update(tuned_glove)\n",
    "\n",
    "    print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "\n",
    "    vocabulary = tokenizer_train.get_vocabulary()\n",
    "    word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    num_tokens = len(vocabulary)\n",
    "    embedding_dim = 100\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "\n",
    "    # Prepare embedding matrix\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "if use_glove:\n",
    "    decoder = RNN_Decoder(embedding_dim, units, num_tokens, embedding_matrix)\n",
    "else:\n",
    "    decoder = RNN_Decoder(embedding_dim, units, tokenizer_train.vocabulary_size(), None)\n",
    "image_features_extract_model = get_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:27<00:00,  5.63it/s]\n"
     ]
    }
   ],
   "source": [
    "img_name_val, cap_val = split_data(img_name_vector_val, cap_vector_val ,\n",
    "                                    image_features_extract_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cap_vector_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x16592c91910>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hazem\\\\Desktop\\\\collage\\\\Graduation project\\\\Unlimited vision app\\\\dataset\\\\coco\\\\val\\\\val2017\\\\000000179765.jpg'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name_vector_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hazem\\\\Desktop\\\\collage\\\\Graduation project\\\\Unlimited vision app\\\\dataset\\\\coco\\\\val\\\\val2017\\\\000000267351.jpg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_name_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeResultFile(img_name_vector_val, encoder, decoder,\n",
    "                   image_features_extract_model, word_to_index_train,\n",
    "                   index_to_word_train):\n",
    "\n",
    "    result_list = []\n",
    "    for i in range(0, len(img_name_vector_val), 5):\n",
    "        id = img_name_vector_val[i].split(\"val2017\\\\\")[1].split(\".\")[0]\n",
    "        cap = predict(img_name_vector_val[i], encoder, decoder, image_features_extract_model,\n",
    "                      word_to_index_train, index_to_word_train)\n",
    "\n",
    "        if cap[-1] == \"<end>\":\n",
    "            cap.remove(\"<end>\")\n",
    "\n",
    "        cap = ' '.join(cap)\n",
    "\n",
    "        temp = {\"image_id\": int(id.lstrip('0')), \"caption\": cap}\n",
    "\n",
    "        result_list.append(temp)\n",
    "\n",
    "    with open('dataset\\coco\\\\result\\\\result.json', 'w') as outfile:\n",
    "        json.dump(result_list, outfile, sort_keys=True)\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = 'dataset\\coco\\\\val\\captions_val2017.json'\n",
    "results_file = 'dataset\\coco\\\\result\\\\result.json'\n",
    "\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        result = json.load(f)\n",
    "else:\n",
    "    result_a = makeResultFile(img_name_vector_val, encoder, decoder,\n",
    "                    image_features_extract_model, word_to_index_train,\n",
    "                    index_to_word_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 51257, 'reflen': 50121, 'guess': [51257, 46257, 41257, 36270], 'correct': [24239, 7564, 2176, 588]}\n",
      "ratio: 1.0226651503361661\n",
      "Bleu_1: 0.473\n",
      "Bleu_2: 0.278\n",
      "Bleu_3: 0.160\n",
      "Bleu_4: 0.090\n",
      "computing METEOR score...\n",
      "METEOR: 0.154\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.345\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.332\n",
      "computing SPICE score...\n",
      "SPICE: 0.099\n"
     ]
    }
   ],
   "source": [
    "# create coco object and coco_result object\n",
    "coco = COCO(annotation_file)\n",
    "coco_result = coco.loadRes(results_file)\n",
    "\n",
    "# create coco_eval object by taking coco and coco_result\n",
    "coco_eval = COCOEvalCap(coco, coco_result)\n",
    "\n",
    "coco_eval.evaluate()\n",
    "\n",
    "# print output evaluation scores\n",
    "# for metric, score in coco_eval.eval.items():\n",
    "#     print(f'{metric}: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fefb53ccb8826f5d221933f4e956154857a1cf678d9c734061c64f9df1cd0fd7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('uvapp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
