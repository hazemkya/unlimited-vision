{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "# from test import *\n",
    "# from models.utilities import *\n",
    "from models.subclasses import *\n",
    "from models.predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static values\n",
    "\n",
    "test_image, _ = load_image(\"testVideos/35506150_cbdb630f4f.jpg\")\n",
    "\n",
    "test_image2, _ = load_image(\"testVideos/IMG_3004.jpg\")\n",
    "\n",
    "#how many frame to play until pause\n",
    "SHOW_FRAME = 60 * 1\n",
    "\n",
    "units = int(config['config']['units'])\n",
    "embedding_dim = int(config['config']['embedding_dim'])\n",
    "\n",
    "vocabulary_size = int(config['config']['vocabulary_size'])\n",
    "\n",
    "\n",
    "use_glove = bool(config['config']['use_glove'])\n",
    "glove_dim = int(config['config']['glove_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = load_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 401581 word vectors.\n",
      "Converted 23871 words (5771 misses)\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "if use_glove:\n",
    "    new_glove_path = f\"./dataset/glove.6B/new_glove.6B.{glove_dim}d.pkl\"\n",
    "    tuned_glove = pickle.load(open(new_glove_path, \"rb\"))\n",
    "    len(tuned_glove)\n",
    "    glove_path = f\"./dataset/glove.6B/glove.6B.{glove_dim}d.txt\"\n",
    "\n",
    "    with open(glove_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            word, coefs = line.split(maxsplit=1)\n",
    "            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "            embeddings_index[word] = coefs\n",
    "\n",
    "    embeddings_index.update(tuned_glove)\n",
    "\n",
    "    print(\"Found %s word vectors.\" % len(embeddings_index))\n",
    "\n",
    "\n",
    "    word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "    num_tokens = len(vocabulary)\n",
    "    embedding_dim = 100\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "\n",
    "    # Prepare embedding matrix\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word =index_vocab(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x20f91dd0190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "if use_glove:\n",
    "    decoder = RNN_Decoder(embedding_dim, units, num_tokens, embedding_matrix)\n",
    "else:\n",
    "    decoder = RNN_Decoder(embedding_dim, units, tokenizer_train.vocabulary_size(), None)\n",
    "    \n",
    "image_features_extract_model = get_feature_extractor()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_image(frame):\n",
    "    img = tf.keras.layers.Resizing(256, 256)(frame)\n",
    "    img = tf.keras.applications.resnet.preprocess_input(img)\n",
    "    result = predict_image(img, encoder, decoder,\n",
    "            image_features_extract_model,\n",
    "            word_to_index, index_to_word)\n",
    "\n",
    "    if result[-1] == '<end>':\n",
    "        result.remove('<end>')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text, fName, count, remove = False, override= True):\n",
    "    tts = gTTS(text=text, lang=\"en\")\n",
    "    filename = f\"TestSamples/{fName}_{count}.mp3\"\n",
    "    if os.path.exists(filename):\n",
    "        if override:\n",
    "            os.remove(filename)\n",
    "        else:\n",
    "            print(\"File exist\")\n",
    "            return\n",
    "        \n",
    "    tts.save(filename)\n",
    "    playsound(filename)\n",
    "    if remove:\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'testVideos/Hare - 81204.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statred capturing\n",
      "Time taken for 1 image 3.7919 sec\n",
      "\n",
      "Time taken for 1 image 3.6179 sec\n",
      "\n",
      "Time taken for 1 image 6.4213 sec\n",
      "\n",
      "Time taken for 1 image 4.5719 sec\n",
      "\n",
      "Time taken for 1 image 4.6402 sec\n",
      "\n",
      "Time taken for 1 image 4.3169 sec\n",
      "\n",
      "Time taken for 1 image 3.9394 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loop over all frames  'space' = next frame | 'q' = quit\n",
    "cap = cv2.VideoCapture(PATH)\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "else:\n",
    "    print(\"Statred capturing\")\n",
    "\n",
    "fName = PATH.split('/')[-1].split('.')[0]\n",
    "count = 0\n",
    "total_frames = 0\n",
    "while cap.isOpened():\n",
    "    HasFrames, frame = cap.read()\n",
    "    #if vidoe is not done do\n",
    "    if HasFrames:\n",
    "        total_frames += 1\n",
    "        cv2.imshow('Video', frame)\n",
    "        #when you reach the pause frame do\n",
    "        if((total_frames % SHOW_FRAME) == 0):\n",
    "            #Caption 'frame'\n",
    "            start = time.time()\n",
    "            # print(frame.shape)\n",
    "            result = predict_from_image(frame)\n",
    "            speak(' '.join(result), fName, count)\n",
    "            count += 1\n",
    "            end = time.time()-start\n",
    "            print(f'Time taken for 1 image {end:.4f} sec\\n')\n",
    "            #press 'E' to get next frame\n",
    "            if(cv2.waitKey(5000) == ord('e')):\n",
    "                continue\n",
    "\n",
    "        if(cv2.waitKey(25) == ord('q')):\n",
    "            break    \n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fefb53ccb8826f5d221933f4e956154857a1cf678d9c734061c64f9df1cd0fd7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('uvapp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
