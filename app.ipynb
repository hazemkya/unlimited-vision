{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "# from test import *\n",
    "# from models.utilities import *\n",
    "from models.subclasses import *\n",
    "from models.predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static values\n",
    "PATH = 'testVideos/IMG_9367.MOV'\n",
    "\n",
    "image, _ = load_image(\"testVideos/35506150_cbdb630f4f.jpg\")\n",
    "\n",
    "#how many frame to play until pause\n",
    "SHOW_FRAME = 60\n",
    "\n",
    "save_path = config[\"config\"][\"save_path\"]\n",
    "\n",
    "units = int(config['config']['units'])\n",
    "embedding_dim = int(config['config']['embedding_dim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name_train, cap_train, img_name_val, cap_val, vocabulary = load_dataset()\n",
    "word_to_index, index_to_word = index_vocab(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN_Encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, len(vocabulary))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x122e21cacd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                           decoder=decoder,\n",
    "                           optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "_, _, image_features_extract_model = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(frame):\n",
    "    img = tf.keras.layers.Resizing(224, 224)(frame)\n",
    "    img = tf.keras.applications.resnet50.preprocess_input(img)\n",
    "    result = predict_image(img, encoder, decoder,\n",
    "            image_features_extract_model,\n",
    "            word_to_index, index_to_word)\n",
    "    temp = Image.fromarray(frame, 'RGB')\n",
    "#     temp.show()\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statred capturing\n",
      "['a', 'car', 'at', 'a', 'city', 'street', 'with', 'a', 'city', 'at', 'a', 'city', 'outside', 'a', 'city']\n",
      "Time taken for 1 image 2.3515 sec\n",
      "\n",
      "['a', 'silver', 'building.', '<end>']\n",
      "Time taken for 1 image 0.1220 sec\n",
      "\n",
      "['a', 'lot', 'of', 'motorcycles', 'are', 'parked', 'on', 'the', 'wall', 'next', 'to', 'the', 'beginning', 'of', 'the']\n",
      "Time taken for 1 image 0.2630 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loop over all frames  'space' = next frame | 'q' = quit\n",
    "cap = cv2.VideoCapture(PATH)\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "else:\n",
    "    print(\"Statred capturing\")\n",
    "\n",
    "total_frames = 0\n",
    "while cap.isOpened():\n",
    "    HasFrames, frame = cap.read()\n",
    "    #if vidoe is not done do\n",
    "    if HasFrames:\n",
    "        total_frames += 1\n",
    "        cv2.imshow('Video', frame)\n",
    "        #when you reach the pause frame do\n",
    "        if((total_frames % SHOW_FRAME) == 0):\n",
    "            #Caption 'frame'\n",
    "            start = time.time()\n",
    "            # print(frame.shape)\n",
    "            predict_all(frame)\n",
    "            print(f'Time taken for 1 image {time.time()-start:.4f} sec\\n')\n",
    "            #press 'E' to get next frame\n",
    "            if(cv2.waitKey(5000) == ord('e')):\n",
    "                continue\n",
    "\n",
    "        if(cv2.waitKey(25) == ord('q')):\n",
    "            break    \n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0855005469a133b1a4fed7e6a9d3300657ffc4061414113a9f065e922aa0ee4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('uvapp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
